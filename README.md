# OpenSIGN
2025년 오픈소스 개발자대회에 출품하는 코드입니다. 

## 프로젝트 소개
Mediapipe 기반의 손 관절 좌표를 프레임 단위로 추출하는 방법을 활용하고,
딥러닝 기반 시계열 제스처 분류 모델을 통해 자음 모음 뿐만 아니라 기본적인 단어가 포함된 수어 동작의 연속 패턴을 인식합니다.
이를 통해 사용자는 마치 타자연습처럼 반복 훈련을 통해 수어 표현을 익힐 뿐만 아니라 한국 수어를 이해하는 기반을 마련할 기회와 실시간 피드백 기반의 자율 학습환경을 얻게 됩니다.

## 개발자 소개
- **이강민**: 팀장, 모델개발 및 UI/UX 설계와 시각 피드백 구현
- **박재현**: 모델개발 및 백엔드 시스템 개발

## 개발 환경

## 개발 기간 및 순서 (2025.7.4 ~ 2025.8.21)
- 기획 및 데이터 수집
- 데이터 전처리 및 기본 모델 학습
- 백엔드 API 개발
- 프론트 앤드 UI 개발
- 시스템 통합 및 동작 구간 탐지
- 사용자 피드백 및 누적 학습 기능 구현
- 최종 테스트, 프로젝트 공개


### 기획 및 데이터 수집
- 해당 프로젝트를 위해 인식할 수어단어, 지화, IDLE 목록을 확정하고, 모든 비디오 데이터를 수집.
- AIhub에서 제공되는 데이터와 직접 웹캠 및 휴대폰 비디오 촬영을 통해 비디오 데이터 수집.

### 데이터 전처리 및 기본 모델 학습

### 백엔드 API 개발

### 프론트 앤드 UI 개발

### 시스템 통합 및 동작 구간 탐지

### 사용자 피드백 및 누적 학습 기능 구현

### 최종 테스트, 프로젝트 공개

